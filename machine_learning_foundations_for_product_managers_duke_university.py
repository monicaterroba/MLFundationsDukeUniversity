# -*- coding: utf-8 -*-
"""Machine Learning Foundations for Product Managers Duke University.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tn76gkFgLVTdUSBEAf3av8QWWbp0uwXA

# ‚ö° Predicci√≥n de la Energ√≠a El√©ctrica Generada en una Planta de Ciclo Combinado

## 1. üì¶ Carga de datos

Importamos el dataset con las lecturas ambientales y la energ√≠a generada.
"""

import pandas as pd

# Cargar el dataset
df = pd.read_csv("CCPP_data.csv")
df.head()

"""## 2. üß† Informaci√≥n general y limpieza de datos

En esta secci√≥n exploramos el dataset para entender su estructura y calidad.
Vamos a revisar:

- Tipos de datos de cada columna.
- Cantidad de registros.
- Presencia de valores nulos.
- Estad√≠sticas descriptivas b√°sicas (media, desviaci√≥n est√°ndar, min, max).

"""

# Ver estructura general del dataset
df.info()

# Mostrar estad√≠sticas b√°sicas
df.describe()

# Verificar si hay valores nulos
df.isnull().sum()

"""## 3. üìä An√°lisis exploratorio de datos (EDA)

El objetivo aqu√≠ es entender c√≥mo se distribuyen las variables y c√≥mo se relacionan con la variable objetivo (`PE`).

Analizaremos:

- La distribuci√≥n de cada variable mediante histogramas.
- La correlaci√≥n entre variables con un mapa de calor.
- La relaci√≥n directa entre cada feature y el target mediante gr√°ficos de dispersi√≥n.

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Histograma de las variables
df.hist(bins=30, figsize=(12, 8), color='skyblue', edgecolor='black')
plt.suptitle("Distribuciones de las variables", fontsize=16)
plt.tight_layout()
plt.show()

# Mapa de calor de correlaci√≥n
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Matriz de correlaci√≥n")
plt.show()

# Gr√°ficos de dispersi√≥n entre cada feature y la variable objetivo
features = ['AT', 'V', 'AP', 'RH']

plt.figure(figsize=(14, 10))
for i, col in enumerate(features):
    plt.subplot(2, 2, i+1)
    sns.scatterplot(x=col, y='PE', data=df)
    plt.title(f'{col} vs PE')

plt.tight_layout()
plt.show()

"""## 4. ‚úÇÔ∏è Divisi√≥n de datos: entrenamiento y prueba

Para evaluar el rendimiento del modelo de forma justa, separamos los datos en dos conjuntos:

- **Entrenamiento (80%)**: se utiliza para ajustar el modelo.
- **Prueba (20%)**: se reserva para evaluar el rendimiento final del modelo con datos no vistos.

La variable objetivo es `PE`, y las variables predictoras son: `AT`, `V`, `AP`, `RH`.

"""

from sklearn.model_selection import train_test_split

# Separar variables predictoras y target
X = df.drop("PE", axis=1)
y = df["PE"]

# Divisi√≥n de datos en entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Verificar tama√±os
print(f"Tama√±o del set de entrenamiento: {X_train.shape}")
print(f"Tama√±o del set de prueba: {X_test.shape}")

"""## 5. üß™ Comparaci√≥n de modelos

Vamos a entrenar y comparar al menos dos modelos utilizando **validaci√≥n cruzada (Cross Validation)** con 5 particiones (K-Fold):

- üîπ **Regresi√≥n Lineal**: modelo base simple y f√°cil de interpretar.
- üîπ **Random Forest Regressor**: modelo de conjunto robusto que captura relaciones no lineales.

La m√©trica principal que usamos durante la validaci√≥n es **RMSE (Root Mean Squared Error)**.

"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
import numpy as np

# Modelo de regresi√≥n lineal
lr = LinearRegression()

# Validaci√≥n cruzada con RMSE negativo (se invierte el signo)
scores_lr = cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')

# Promedio de los errores
print("Linear Regression RMSE (CV):", -np.mean(scores_lr))

from sklearn.ensemble import RandomForestRegressor

# Modelo de Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)

# Validaci√≥n cruzada con RMSE
scores_rf = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')

# Promedio de los errores
print("Random Forest RMSE (CV):", -np.mean(scores_rf))

"""## 6. ‚úÖ Evaluaci√≥n del modelo final

Seleccionamos el modelo con mejor rendimiento durante la validaci√≥n cruzada: **Random Forest**.

Ahora lo entrenamos con todo el conjunto de entrenamiento y lo evaluamos en el conjunto de prueba usando las siguientes m√©tricas:

- **RMSE**: Ra√≠z del error cuadr√°tico medio
- **MAE**: Error absoluto medio
- **R¬≤**: Coeficiente de determinaci√≥n

Tambi√©n graficamos las predicciones vs los valores reales para observar la precisi√≥n del modelo.

"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Entrenar el modelo con todo el set de entrenamiento
rf.fit(X_train, y_train)

# Realizar predicciones sobre el set de prueba
y_pred = rf.predict(X_test)

# Calcular m√©tricas corregidas
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Mostrar resultados
print(f"RMSE en test: {rmse:.2f}")
print(f"MAE en test: {mae:.2f}")
print(f"R¬≤ en test: {r2:.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.scatter(y_test, y_pred, alpha=0.5, edgecolor='k')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel("Valores reales (PE)")
plt.ylabel("Predicciones (PE)")
plt.title("Comparaci√≥n: Predicciones vs Valores Reales")
plt.grid(True)
plt.tight_layout()
plt.show()

"""## 7. üßæ Conclusi√≥n

- Se construy√≥ un modelo de aprendizaje supervisado para predecir la energ√≠a el√©ctrica generada (`PE`) en una planta de ciclo combinado.
- Se compararon dos algoritmos:
  - üîπ Regresi√≥n Lineal (baseline)
  - üîπ Random Forest (modelo final seleccionado)
- Random Forest obtuvo el mejor desempe√±o, con un **RMSE de 3.25**, **MAE de 2.33** y un **R¬≤ de 0.9637** en el conjunto de prueba.
- La precisi√≥n del modelo lo convierte en una herramienta √∫til para estimar el output energ√©tico a partir de variables ambientales.
- Este enfoque puede ayudar a mejorar la eficiencia operativa de plantas de energ√≠a al anticipar variaciones de producci√≥n bajo distintas condiciones clim√°ticas.

"""